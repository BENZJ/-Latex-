
% !Mode:: "TeX:UTF-8"
% !TEX program = LATEXMK
\documentclass[]{my}

\usepackage{multicol}

% \usepackage{geometry}

% \geometry{a4paper,left=2cm,right=2cm,top=2.54cm,bottom=2.54cm}
\begin{document}
% \let\songti\relax
% \begin{CJK}{UTF8}{gbsn}
    \zihao{-5}\heiti{中图法分类号}:\zihao{-5}\songti{(此号在中国图书馆分类法中查)}  \zihao{-5}\heiti{文献标识码}:\zihao{-5}\songti{A}   \zihao{-5}\heiti{文章编号}:\zihao{-5}\songti{1006-8961(年) -}

    \begin{center}
        \zihao{2}\songti {融合深度模型和传统模型的显著性检测}
    \end{center}

    \begin{cabstract}
        显著性检测是图像和视觉领域一个基础问题，传统模型对于显著性物体的边界保留较好，但是对显著性目标的自信度不够高，召回率低，而深度学习模型对于显著性物体的自信度高，但是其结果边界粗糙，准确率较低。针对这两种模型各自的优缺点，提出了一种显著性模型以综合利用两种方法的优点并抑制各自的不足。方法 首先改进最新的密集卷积网络，训练了一个基于该网络的全卷积网络（FCN）显著性模型，同时选取一个现有的基于超像素的显著性回归模型，在得到两种模型的显著性结果图后，提出一种融合算法，融合两种方法的结果以得到最终优化结果，该算法通过显著性结果Hadamard积和像素间显著性值的一对一非线性映射，将FCN结果与传统模型的结果相融合。结果 实验在4个数据集上与最新的10种方法进行了比较，在HKU-IS数据集中，相比于性能第2的模型，F值提高了2.6\%；在MSRA数据集中，相比于性能第2的模型，F值提高了2.2\%，MAE降低了5.6\%；在DUT-OMRON数据集中，相比于性能第2的模型，F值提高了5.6\%，MAE降低了17.4\%。同时也在MSRA数据集中进行了对比实验以验证融合算法的有效性，对比实验结果证明提出的融合算法改善了显著性检测的效果。结论 本文所提出的显著性模型，综合了传统模型和深度学习模型的优点，使显著性检测结果更加准确。
    \end{cabstract}


    \begin{ckeywords}
        显著性检测；密集卷积网络；全卷积网络；融合算法；Hadamard积
    \end{ckeywords}   

    \clearpage
  
% \footnote{\noindent \textbf{收稿日期}：2000-06-30；\textbf{修回日期}：2000-11-16\\ 
% \noindent\textbf{基金项目}：``九五''国家科技攻关资助项目(96-B02-03-05)\\ \textbf{Supported by}：}.
    
% \end{CJK}
\begin{multicols}{2}
    1）类似一个小综述，应包括国际、国内最新研究进展，现存问题、方法局限或研究空白等，以此提出论文的切入点等。


 2）每条引文应列出精准的参考文献，避免出现一处笼统标注多个文献的情况。文献引用方式请采用（作者，出版年）的形式，样例如：“能量和碳的循环(Jung等 ，2010)”。   



3) 条理清晰，避免大量文献的无序堆砌，对国内外开展的相关工作进行系统梳理和分析(无需在引言中介绍文章的结构，正文5号宋体)

1）变量：变量用斜体,矩阵,矢量,向量,集合,数组,图像用斜体加粗,R(实数集),Z(整数集),N(自然数集)用正体加粗,且各变量要求加以说明，标准函数用正体。样例如：


首先，用RN来表示N维空间。用Xn，…，X2，X1来表示N维空间RN的N个维。把从N维空间坐标转换成的1维空间坐标值叫做Hilbert码，记为：H-code。本文约定若一条Hilbert 曲线可以填充一个2m 2m … 2m (2mN)的N维空间，则称该Hilbert曲线为一个N维m代Hilbert曲线，用HN m表示。


2）公式：全文统一从1递增编序号，样例样例如：式（1）…，所有公式及变量建议使用MathType编辑器编辑，同时，公式后需对每一个首次出现的变量加以说明。样例如：


通过矩阵外积将每一个位置点的特征输出汇聚，也就是在 区域 和 的双线性特征的融合


\end{multicols}
\end{document}
